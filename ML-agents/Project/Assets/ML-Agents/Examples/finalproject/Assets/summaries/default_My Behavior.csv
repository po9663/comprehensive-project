Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,2.0794213,0.00029701597,0.08011346,6602.923889385723,985.0,5473.633241732915
20000,2.078111,0.00029100996,1.6271155,15462.127515181714,985.0,17139.89029072821
30000,2.0712247,0.00028500392,4.161482,6188.877848816663,985.0,5997.087656645477
40000,2.0714445,0.00027899793,4.5545964,8690.429862091132,985.0,6150.164791797101
50000,2.068073,0.0002730043,7.529676,17549.689639729346,985.0,18525.666314542294
60000,2.0608063,0.00026701053,12.95249,12229.473807388917,985.0,12229.473538646102
70000,2.0493124,0.00026100455,20.376272,24432.34132930748,985.0,24432.341347849368
80000,2.0359378,0.00025499854,34.055683,36681.83955019582,985.0,36681.83870850205
90000,2.0345888,0.00024899252,41.451756,26217.148866577445,985.0,26217.14784119129
100000,2.0106874,0.00024298654,57.572365,32236.85358566288,985.0,32236.85235259235
110000,2.012157,0.00023699977,59.131817,19578.426350991427,985.0,19578.42587016821
120000,1.980237,0.00023101298,79.46278,20592.438505090027,985.0,20592.438502970337

Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,2.0794137,0.00029701597,-0.02835894,5533.232919435017,985.0,5465.28659826186
20000,2.0791097,0.00029100996,0.7980956,9726.608677048609,985.0,10177.019383855164
30000,2.0777268,0.00028500392,2.3314133,7309.46189406421,985.0,5224.587951192259
40000,2.0731156,0.00027899793,4.2827997,3108.2479138392955,985.0,4862.5728096172215
50000,2.069287,0.0002730043,5.1200504,6235.679914089955,985.0,6106.724905195832
60000,2.0659559,0.00026701053,6.526953,4227.683914796263,985.0,4227.6838333949445
70000,2.058843,0.00026100455,7.061493,-10.424999750219285,985.0,-10.42499889433384
80000,2.0551357,0.00025499854,8.377024,13106.825808499381,985.0,13106.82636666
90000,2.0622654,0.00024899252,9.195405,-10.247999753803015,985.0,-10.24799885749817
